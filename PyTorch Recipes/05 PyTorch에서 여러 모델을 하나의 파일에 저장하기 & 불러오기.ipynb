{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e045010d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T09:45:22.824312Z",
     "start_time": "2022-04-04T09:45:22.812578Z"
    }
   },
   "outputs": [],
   "source": [
    "# 결과 확인을 용이하게 하기 위한 코드\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46389f47",
   "metadata": {},
   "source": [
    "- [05 PyTorch에서 여러 모델을 하나의 파일에 저장하기 & 불러오기](https://tutorials.pytorch.kr/recipes/recipes/saving_multiple_models_in_one_file.html)\n",
    "- 여러 모델을 저장하고 불러오는 것은 이전에 학습했던 모델들을 재사용하는데 도움이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b39c0",
   "metadata": {},
   "source": [
    "# 개요\n",
    "- GAN이나 sequence-to-sequence model, ensemble of models와 같이 여러 `torch.nn.Modules`로 구성된 모델을 저장할 때는 각 모델의 state_dict와 해당 optimizer의 사전을 저장해야 함\n",
    "- 또한, 학습을 재개하는데 필요한 다른 항목들을 사전에 추가할 수 있음\n",
    "- 모델들을 불러올 때는 먼저 모델들과 옵티마이저를 초기화하고 `torch.load()`를 사용하여 사전을 불러옴\n",
    "- 이후 원하는대로 저장한 항목들을 사전에 조회하여 접근할 수 있음\n",
    "- PyTorch를 사용하여 여러 모델들을 하나의 파일에 어떻게 저장하고 불러오는지 살펴볼 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015578ba",
   "metadata": {},
   "source": [
    "# 단계(Steps)\n",
    "1. 데이터 불러올 때 필요한 라이브러리들 불러오기\n",
    "2. 신경망을 구성하고 초기화하기\n",
    "3. 옵티마이저 초기화하기\n",
    "4. 여러 모델들 저장하기\n",
    "5. 여러 모델들 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3eec1",
   "metadata": {},
   "source": [
    "## 데이터 불러올 때 필요한 라이브러리들 불러오기\n",
    "- `torch`와 여기 포함된 `torch.nn`과 `torch.optim`을 사용할 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa68cbea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T10:04:30.496379Z",
     "start_time": "2022-04-04T10:04:30.122275Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76875444",
   "metadata": {},
   "source": [
    "## 신경망을 구성하고 초기화하기\n",
    "- 예를 들어, 이미지를 학습하는 신경망을 만들어볼 것임 \n",
    "- 모델을 저장할 2개의 변수들을 만들어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16730d9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T10:08:41.079568Z",
     "start_time": "2022-04-04T10:08:41.071549Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "netA = Net()\n",
    "netB = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af8f73",
   "metadata": {},
   "source": [
    "## 옵티마이저 초기화하기\n",
    "- 생성한 모델들 각각에 momentum을 갖는 SGD를 사용할 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6440de38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T10:09:56.093589Z",
     "start_time": "2022-04-04T10:09:56.090831Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizerA = optim.SGD(netA.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizerB = optim.SGD(netB.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2c361",
   "metadata": {},
   "source": [
    "## 여러 모델들 저장하기\n",
    "- 관련된 모든 정보들을 모아서 사전을 구성함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e30995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T10:12:17.591765Z",
     "start_time": "2022-04-04T10:12:17.585283Z"
    }
   },
   "outputs": [],
   "source": [
    "# 저장할 경로 지정\n",
    "PATH = 'model.pt'\n",
    "torch.save({'modelA_state_dict': netA.state_dict(),\n",
    "            'modelB_state_dict': netB.state_dict(),\n",
    "            'optimizerA_state_dict': optimizerA.state_dict(),\n",
    "            'optimizerB_state_dict': optimizerB.state_dict()}\n",
    "           , PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04203c",
   "metadata": {},
   "source": [
    "## 여러 모델들 불러오기\n",
    "- 먼저 모델과 옵티마이저를 초기화한 뒤, 사전 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363a7bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T10:15:41.133668Z",
     "start_time": "2022-04-04T10:15:41.117901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA = Net()\n",
    "modelB = Net()\n",
    "optimModelA = optim.SGD(modelA.parameters(), lr=0.001, momentum=0.9)\n",
    "optimModelB = optim.SGD(modelB.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "modelB.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])\n",
    "\n",
    "modelA.eval()\n",
    "modelB.eval()\n",
    "# 또는\n",
    "modelA.train()\n",
    "modelB.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10d277",
   "metadata": {},
   "source": [
    "- 추론(inference)을 실행하기 전에 `model.eval()`을 호출하여 dropout과 batch normalization layer를 evaluation 모드로 바꾸기\n",
    "    - 이것을 빼먹으면 일관성 없는 추론 결과를 얻게 됨\n",
    "- 만약 학습을 계속하길 원한다면 `model.train()`을 호출하여 이 층(layer)들이 학습 모드인지 확인(ensure)하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
