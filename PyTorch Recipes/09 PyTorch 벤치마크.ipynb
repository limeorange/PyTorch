{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10cfcd58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T01:02:42.011253Z",
     "start_time": "2022-04-06T01:02:42.002956Z"
    }
   },
   "outputs": [],
   "source": [
    "# 결과 확인을 용이하게 하기 위한 코드\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e0361",
   "metadata": {},
   "source": [
    "- [09 PyTorch 벤치마크](https://tutorials.pytorch.kr/recipes/recipes/benchmark.html)\n",
    "- PyTorch benchmark모듈을 사용하여 코드 성능을 측정하고 비교하는 빠른 시작 가이드를 제공할 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f5e537",
   "metadata": {},
   "source": [
    "# 소개\n",
    "- 벤치마킹은 코드 작성에서 중요한 단계임\n",
    "- 코드가 성능 기대치를 충족하는지 검증하고 동일한 문제를 해결하기 위한 다양한 접근 방식을 비교하며 성능 회귀를 방지하는 데 도움이 됨\n",
    "\n",
    "\n",
    "- `timeit` Python 내장 모듈을 포함하여 PyTorch 코드를 벤치마킹할 때 많은 옵션이 있음\n",
    "- 그러나 PyTorch 코드 벤치마킹에는 스레드 수 관리 및 CUDA 장치 동기화와 같이 쉽게 간과될 수 있는 많은 주의 사항이 있음\n",
    "- 게다가 벤치마킹을 위해 Tensor 입력을 생성하는 것은 꽤 지루할 수 있음\n",
    "\n",
    "\n",
    "- 이 레시피는 PyTorch `benchmark`모듈을 사용하여 일반적인 실수를 피하는 동시에 다른 코드의 성능을 더 쉽게 비교하고 벤치마킹을 위한 입력을 생성하는 방법을 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcdcb2",
   "metadata": {},
   "source": [
    "# 단계\n",
    "1. 벤치마킹할 함수 정의\n",
    "2. 벤치마킹 `timeit.Timer`\n",
    "3. 벤치마킹 `torch.utils.benchmark.Timer`\n",
    "4. 차단된 자동 범위를 사용한 벤치마킹\n",
    "5. 벤치마크 결과 비교\n",
    "6. 벤치마크 결과 저장/불러오기\n",
    "7. 퍼지 매개변수 로 입력 생성\n",
    "8. Callgrind로 명령어 카운트 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b4a9b",
   "metadata": {},
   "source": [
    "## 벤치마킹할 함수 정의\n",
    "- 이 글을 쓰는 시점에서 `torch.dot`은 일괄 처리 모드를 지원하지 않으므로 기존 `torch` 연산자를 사용하여 구현하는 두 가지 접근 방식을 비교할 것임\n",
    "- 하나는 `mul`과 `sum`의 조합을 사용하고, 다른 하나는 `bmm`을 사용\n",
    "\n",
    "\n",
    "- cf)\n",
    "- `mm` : matrix multiplication으로, [n, m] x [m,p] = [n,p] 를 구현함\n",
    "- `bmm` : batch matrix multiplication으로, 두 operand가 모두 batch일 때 사용함\n",
    "    - [B, n, m] x [B, m, p] = [B, n, p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8301ac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T01:05:49.845993Z",
     "start_time": "2022-04-06T01:05:48.708894Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batched_dot_mul_sum(a, b):\n",
    "    '''Computes batched dot by multiplying and summing'''\n",
    "    return a.mul(b).sum(-1)\n",
    "\n",
    "def batched_dot_bmm(a, b):\n",
    "    '''Computes batched dot by reducing to bmm'''\n",
    "    a = a.reshape(-1, 1, a.shape[-1])\n",
    "    b = b.reshape(-1, b.shape[-1], 1)\n",
    "    return torch.bmm(a, b).flatten(-3)\n",
    "\n",
    "# Input for benchmarking\n",
    "x = torch.randn(10000, 64)\n",
    "\n",
    "# Ensure that both functions compute the same output\n",
    "assert batched_dot_mul_sum(x, x).allclose(batched_dot_bmm(x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee34a14",
   "metadata": {},
   "source": [
    "## 벤치마킹 `timeit.Timer`\n",
    "- 먼저 Python의 내장 `timeit` 모듈을 사용하여 코드를 벤치마킹 해볼 것임\n",
    "- 여기에서 벤치마크 코드를 단순하게 유지하여 `timeit`과 `torch.utils.benchmark`의 기본값을 비교할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb908107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T01:19:01.877890Z",
     "start_time": "2022-04-06T01:19:01.827435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul_sum(x, x): 202.7 us\n",
      "bmm(x, x): 262.0 us\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "t0 = timeit.Timer(\n",
    "    stmt = 'batched_dot_mul_sum(x, x)',\n",
    "    setup = 'from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = timeit.Timer(\n",
    "    stmt = 'batched_dot_bmm(x, x)',\n",
    "    setup = 'from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "print(f'mul_sum(x, x): {t0.timeit(100) / 100 * 1e6:>5.1f} us')\n",
    "print(f'bmm(x, x): {t1.timeit(100) / 100 * 1e6:>5.1f} us')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c5405",
   "metadata": {},
   "source": [
    "# 벤치마킹 `torch.utils.benchmark.Timer`\n",
    "- PyTorch `benchmark` 모듈은 이전에 `timeit` 모듈을 사용한 적이 있는 사람들에게 익숙하도록 설계됨\n",
    "- 그러나 기본값들은 PyTorch 코드를 벤치마킹하는 것을 더 쉽고 안전하게 해줌\n",
    "- 먼저 위와 동일한 기본 API를 비교해볼 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bd83a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T01:22:03.764520Z",
     "start_time": "2022-04-06T01:22:03.402597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7fc0b0ea0910>\n",
      "batched_dot_mul_sum(x, x)\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  126.32 us\n",
      "  1 measurement, 100 runs , 1 thread\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7fc0b32a0400>\n",
      "batched_dot_bmm(x, x)\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  256.96 us\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x})\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x})\n",
    "\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c6066",
   "metadata": {},
   "source": [
    "- API는 기본 기능에 대해 동일하지만 몇 가지 중요한 차이점이 있음\n",
    "- `benchmark.Timer.timeit()`은 총 런타임과 달리 실행당 시간을 반환함\n",
    "- PyTorch `benchmark` 모듈은 결과 인쇄를 위한 형식화된 문자열 표현도 제공함\n",
    "\n",
    "\n",
    "- 또 다른 중요한 차이점, 즉 결과가 다른 이유는 PyTorch 벤치마크 모듈이 기본적으로 단일 스레드에서 실행되기 때문임\n",
    "- num_threads 인수로 스레드 수를 변경할 수 있음\n",
    "\n",
    "\n",
    "- `torch.utils.benchmark.Timer`은 label, sub_label, description 및 env를 포함한 몇 가지 추가 인수를 취함\n",
    "- 이 인수는 반환된 측정 개체의 `_repr__`를 변경하고 결과를 그룹화하는 데 사용됨(나중에 자세히 설명)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c08182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T01:28:17.650941Z",
     "start_time": "2022-04-06T01:28:17.600378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking on 3 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7fc0b449a1f0>\n",
      "Multithreaded batch dot: Implemented using mul and sum\n",
      "setup: from __main__ import batched_dot_mul_sum\n",
      "  171.79 us\n",
      "  1 measurement, 100 runs , 3 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7fc0b3280af0>\n",
      "Multithreaded batch dot: Implemented using bmm\n",
      "setup: from __main__ import batched_dot_bmm\n",
      "  255.45 us\n",
      "  1 measurement, 100 runs , 3 threads\n"
     ]
    }
   ],
   "source": [
    "num_threads = torch.get_num_threads()\n",
    "print(f'Benchmarking on {num_threads} threads')\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='batched_dot_mul_sum(x, x)',\n",
    "    setup='from __main__ import batched_dot_mul_sum',\n",
    "    globals={'x': x},\n",
    "    num_threads=num_threads,\n",
    "    label='Multithreaded batch dot',\n",
    "    sub_label='Implemented using mul and sum')\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='batched_dot_bmm(x, x)',\n",
    "    setup='from __main__ import batched_dot_bmm',\n",
    "    globals={'x': x},\n",
    "    num_threads=num_threads,\n",
    "    label='Multithreaded batch dot',\n",
    "    sub_label='Implemented using bmm')\n",
    "\n",
    "print(t0.timeit(100))\n",
    "print(t1.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c458186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 보류..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
