{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d643f2e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T08:51:23.459907Z",
     "start_time": "2022-04-05T08:51:23.447160Z"
    }
   },
   "outputs": [],
   "source": [
    "# 결과 확인을 용이하게 하기 위한 코드\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c10b7b",
   "metadata": {},
   "source": [
    "- [07 PyTorch에서 변화도를 0으로 만들기](https://tutorials.pytorch.kr/recipes/recipes/zeroing_out_gradients.html)\n",
    "- 신경망을 구축할 때는 변화도를 0으로 만들어 주는 것이 좋음\n",
    "- 기본적으로 .backward()를 호출할 때마다 변화도가 버퍼에 쌓이기 때문임 (덮어쓰지 않는다는 의미 = 누적돼서 더해짐)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd10f2f",
   "metadata": {},
   "source": [
    "# 개요\n",
    "- 신경망을 학습시킬 때, 경사 하강법을 거쳐 모델 정확도를 높일 수 있음\n",
    "- 경사 하강법은 간단히 설명해 모델의 가중치와 편향을 약간씩 수정하면서 손실(또는 오류)를 최소화하는 과정임\n",
    "\n",
    "\n",
    "- `torch.Tensor`는 PyTorch의 핵심이 되는 클래스임\n",
    "- 텐서를 생성할 때 `.requires_grad` 속성을 `True`로 설정하면, 텐서에 가해진 모든 연산을 추적함\n",
    "- 뒤따르는 모든 역전파 단계에서도 이 텐서의 변화도는 `.grad` 속성에 누적될 것임\n",
    "- 모든 변화도의 축적 또는 합은 손실 텐서에서 `.backward()`를 호출할 때 계산됨\n",
    "\n",
    "\n",
    "- 텐서의 변화도를 0으로 만들어 주어야 하는 경우도 있음\n",
    "- 예를 들어 학습 과정 반복문을 시작할 때, 누적되는 변화도를 정확하게 추적하기 위해서는 변화도를 우선 0으로 만들어 주어야 함\n",
    "- 이 레시피에서는 PyTorch 라이브러리를 사용하여 변화도를 0으로 만드는 방법을 배워볼 것임\n",
    "- PyTorch에 내장된 CIFAR10 데이터셋에 대하여 신경망을 훈련시키는 과정을 통해 알아볼 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8059c607",
   "metadata": {},
   "source": [
    "# 설정\n",
    "- 이 레시피에는 데이터를 학습시키는 내용이 포함되어 있기 때문에, 실행 가능한 노트북 파일이 있다면 런타임을 GPU 또는 TPU로 전환하는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a76c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T08:51:23.464367Z",
     "start_time": "2022-04-05T08:51:23.462198Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f773286",
   "metadata": {},
   "source": [
    "# 단계(Steps)\n",
    "- 1단계부터 4단계까지는 학습을 위한 데이터와 신경망을 준비하며, 5단계에서 변화도를 0으로 만들어 줌\n",
    "- 이미 준비한 데이터와 신경망이 있다면 5단계로 건너뛰어도 좋음\n",
    "\n",
    "1. 데이터를 불러오기 위해 필요한 모든 라이브러리 import 하기\n",
    "2. 데이터셋 불러오고 정규화하기\n",
    "3. 신경망 구축하기\n",
    "4. 손실 함수 정의하기\n",
    "5. 신경망을 학습시킬 때 변화도 0으로 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fceff",
   "metadata": {},
   "source": [
    "## 데이터를 불러오기 위해 필요한 모든 라이브러리 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee0a009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T08:51:23.967198Z",
     "start_time": "2022-04-05T08:51:23.466007Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6eea78",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오고 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e40211e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T08:51:56.300308Z",
     "start_time": "2022-04-05T08:51:56.298141Z"
    }
   },
   "outputs": [],
   "source": [
    "# 아래 셀 에러 해결 코드 2 -> 효과 굳\n",
    "# https://hello-bryan.tistory.com/315\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ae4a43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T09:02:52.468855Z",
     "start_time": "2022-04-05T08:51:57.130460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff789d",
   "metadata": {},
   "source": [
    "## 신경망 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea07bff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T09:02:52.476033Z",
     "start_time": "2022-04-05T09:02:52.470769Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # in_channels, out_channels, kernel_size\n",
    "        self.pool = nn.MaxPool2d(2, 2) # kernel_size, stride\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # in_features, out_features\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f275120",
   "metadata": {},
   "source": [
    "## 손실 함수와 옵티마이저 정의하기\n",
    "- 분류를 위한 Cross-Entropy 손실 함수와 모멘텀을 설정한 SGD 옵티마이저를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd08d0f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T09:02:52.482567Z",
     "start_time": "2022-04-05T09:02:52.478212Z"
    }
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a88bdf",
   "metadata": {},
   "source": [
    "## 신경망을 학습시키는 동안 변화도를 0으로 만들기\n",
    "- 데이터 iterator를 순회하면서, 신경망에 입력을 주고 최적화할 것임\n",
    "- 데이터의 entity 각각의 변화도를 0으로 만들어줘야 함\n",
    "- 신경망을 학습시킬 때 불필요한 정보를 추적하지 않도록 하기 위함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54f0395b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T09:10:45.733361Z",
     "start_time": "2022-04-05T09:09:29.940491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.202\n",
      "[1,  4000] loss: 1.894\n",
      "[1,  6000] loss: 1.675\n",
      "[1,  8000] loss: 1.597\n",
      "[1, 10000] loss: 1.532\n",
      "[1, 12000] loss: 1.467\n",
      "[2,  2000] loss: 1.402\n",
      "[2,  4000] loss: 1.379\n",
      "[2,  6000] loss: 1.335\n",
      "[2,  8000] loss: 1.305\n",
      "[2, 10000] loss: 1.288\n",
      "[2, 12000] loss: 1.262\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): # 전체 데이터셋의 학습을 2번 반복하기 \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 입력 받기 : 데이터는 [inputs, labels] 형태의 리스트\n",
    "        x_train, y_train = data\n",
    "        \n",
    "        # 파라미터 변화도를 0으로 만들기\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 순전파 + 역전파 + 최적화\n",
    "        predict = net(x_train)\n",
    "        loss = criterion(predict, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 통계 출력\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # 미니배치 2000개 마다 출력\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f63d57a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T09:12:29.345414Z",
     "start_time": "2022-04-05T09:11:15.568529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 23.967\n",
      "[1,  4000] loss: 105.314\n",
      "[1,  6000] loss: 205.509\n",
      "[1,  8000] loss: 290.417\n",
      "[1, 10000] loss: 416.583\n",
      "[1, 12000] loss: 472.221\n",
      "[2,  2000] loss: 571.300\n",
      "[2,  4000] loss: 829.021\n",
      "[2,  6000] loss: 680.068\n",
      "[2,  8000] loss: 1051.190\n",
      "[2, 10000] loss: 954.784\n",
      "[2, 12000] loss: 1013.622\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# if 변화도를 0으로 만들어주지 않으면? (.zero_grad()를 적용시키지 않으면..)\n",
    "for epoch in range(2): # 전체 데이터셋의 학습을 2번 반복하기 \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 입력 받기 : 데이터는 [inputs, labels] 형태의 리스트\n",
    "        x_train, y_train = data\n",
    "        \n",
    "        # 파라미터 변화도를 0으로 만들기\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "        # 순전파 + 역전파 + 최적화\n",
    "        predict = net(x_train)\n",
    "        loss = criterion(predict, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 통계 출력\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # 미니배치 2000개 마다 출력\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                 (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8733cd",
   "metadata": {},
   "source": [
    "- `model.zero_grad()`를 사용해도 변화도를 0으로 만들 수 있음\n",
    "- 이는 옵티마이저에 모든 모델 파라미터가 포함되는 한 `optimizer.zero_grad()`를 사용하는 것과 동일함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
